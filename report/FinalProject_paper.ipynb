{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Python Implementation of Stochastic Gradient Hamiltonian Monte Carlo with example applications from simulated and real data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "\n",
    "#### (INSTRUCTIONS ARE: 250 words or less. Identify 4-6 key phrases.)\n",
    "\n",
    "We implement the Stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm described in the paper *Stochastic Gradient Hamiltonian Monte Carlo* by Chen et al. (2014). This particular Hamiltonian Monte Carlo (HMC) sampling method allows for a sampling 'Big Data' through the use of a noisy gradient term calculated using minibatches of the full data set. We include python implementations of the algorithm; a description of the changes made and performance gains in each successive version may be found in the **Optimization** section of this document. We include a simulated example showing the performance of the algorithm in sampling the mean parameters of a two-component mixture of normals, and a real-world example showing **FIXME**. **FIXME** this needs more stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Background\n",
    "\n",
    "Hamiltonian Monte Carlo (HMC) sampling methods allow for proposing distant points in space with high acceptance probabilities. Hamiltonian Monte Carlo treats the probability density as a physical system being explored by a moving object. The object conserves energy overall, while trading between potential energy (in high probability regions) and momentum. HMC methods incorporate gradient information into the proposal distribution, which is especially advantageous for sampling a probability distribution with high correlations. This enables more efficient exploration of the space of interest than random walks, while still being in a Metropolis-Hastings framework.\n",
    "\n",
    "The paper *Stochastic Gradient Hamiltonian Monte Carlo* by Chen et al. (2014) develops a variant of HMC that sidesteps the computational limitation of HMC methods that comes from having to compute the gradient when the data are large. Specifically, the authors use a stochastic gradient and introduce a friction term that allows the algorithm to maintain the desired target distribution and invariance properties.\n",
    "\n",
    "This algorithm can be applied in any situation in which MCMC methods are needed, but is particularly useful in cases when the usual random walk methods tends to produce highly dependent samples (e.g., when there are high correlation between variables) or very low acceptance probabilities (e.g. when the sample space is very high dimensional). It also allows for scaling of Bayesian methods, with the use of minibatches of data.\n",
    "\n",
    "Other developments to improve the flexibility of HMC include the \"No U-Turn\" sampler and Riemann manifold HMC. The authors argue that their Stochastic gradient Hamiltonian Monte Carlo (SGHMC) algorithm is an efficiency improvement to traditional HMC orthogonal to these other approaches, and thus could be combined with them to yield even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of algorithm\n",
    "\n",
    "The Stochastic Gradient HMC algorithm is complex in its derivation, but simple in implementation. In words, the algorithm begins when the sampler is initialized. The algorithm draws a specified number of discrete samples by moving around the targeted probability distribution. In standard HMC each move is a deterministic function of the current location and momentum. In SGHMC, random noise is added to account for the stochastic estimation of the target distribution. In addition, during each move a friction term reduces the momentum for stability. Computationally, the algorithm is:\n",
    "\n",
    "\n",
    "*Initialize ($\\theta_0$, $v_0$, $\\alpha$, $\\eta$, $\\hat{\\beta}$)*\n",
    "\n",
    "**for t = 1,2,... :**\n",
    "    \n",
    "$\\qquad \\theta_i = \\theta_{i-1} + v$\n",
    "    \n",
    "$\\qquad v = v - \\eta \\nabla \\tilde{U(}x) - \\alpha v + N(0, 2(\\alpha - \\hat{\\beta}))$\n",
    "\n",
    "\n",
    "**end **\n",
    "\n",
    "The above computational algorithm represents the Hamiltonian dynamics, re-expressed in terms more familiar to Stochastic Gradient Descent. $\\tilde{U}(x)$ is the minibatch approximation to the gradient, $\\eta$ is the learning rate, $\\alpha$ is the friction constant, and $\\hat{\\beta}$ is the approximation to the noise introduced by the stochastic gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FIXME** should we put our python implementation of the algorithm here??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe optimization for performance\n",
    "\n",
    "Vectorization was performed in the original algorithm, so we don't have any optimization results for vectorized vs. non-vectorized Python versions of the sampler. Things we did to optimize performance relative to our original algorithm (see optimization_work.ipynb) include:\n",
    "1. An algorithmic performance improvement in multivariate normal sampling. We obtain improvement through the use of Cholesky decomposition based multivariate normal sampling with pre-computation (outside of the main sampler loop) of the Cholesky decomposition of covariance matrices needed to sample from the relevant multivariate normals.\n",
    "2. JIT compilation of our main SGHMC sampling algorithm (we tried the data batching code with and without JIT compilation for comparison within the JIT-compiled algorithm).\n",
    "3. Re-writing the main algorithm, data batching, and gradient functions in C++ and using pybind11 to wrap them.\n",
    "\n",
    "|                            | Original     | Efficiency improvements | Numpy version (main algorithm only) | Numpy version (main algorithm and data batching) | C++ version   |\n",
    "|----------------------------|--------------|-------------------------|-------------------------------------|--------------------------------------------------|---------------|\n",
    "| Figure 1 Example           | 23.5 (0.297) | 3.52 (0.091)            | 4.81 (0.465)                        |                                                  | 0.197 (0.003) |\n",
    "| Mixture of Normals Example | 22.7 (0.144) | 21.7 (0.253)            | 22.0 (0.176)                        | 22.1 (0.062)                                     | 0.019 (0.000) |\n",
    "\n",
    "Table 1 gives the time taken for the sampler to draw 50,000 samples from the target distribution (Figure 1 example) or 2,000 samples from the target (with 500 iterations over 4 size-50 data batches, in the mixtures of normals example). Times shown are the mean (standard deviation) across 7 runs in seconds. Tuning parameters are chosen to be the same as those described in the **Applications to simulated data sets** section below. Note that the deteriorated performance of the JIT-compiled version in the case of the Figure 1 example may be due to the fact that the data are not being resampled here (rather, artificial noise is being injected), so the overhead of JIT may outweigh the benefits. Since data batching are not performed, the second numpy version is the same as the first. Note that the C++ version of the mixture of normals example yielded unstable behavior so it is possible we have a small bug in the data batching section of the C++ code, but computation times should still be relevant.\n",
    "\n",
    "We see that the C++ version of the code is 11,839% faster (calculated as (old - new) / new x 100%) than the original version for the Figure 1 example and 118,308% faster than the original for the mixtures of normals example. Profiling showed expensive computation times for the auto-gradient calculation done by the `jacobian` function we used from the `autograd` package in the Python version of the code. The JIT-compiled version was not able to improve as much relative to the original, likely because it could not automatically C++-ify these expensive computations, whereas explicitly coding the algorithm in C++ allowed us to write the gradient functions by hand.\n",
    "\n",
    "If we were working with extremely large data sets, distributed computing would be an optimization avenue to explore. However, we used a small enough data example that local computation was sufficient.\n",
    "\n",
    "As the algorithm is a MCMC sampler, parallelization is not possible because we have dependence within each chain. An option could be to run multiple chains and parallelize over the number of chains, but this would only give gains up to the number of chains run rather than improving the speed of the underlying algorithm itself. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications to simulated data sets\n",
    "\n",
    "**Are there specific inputs that give known outuputs (e.g. there might be closed form solutions for special input cases)? How does the algorithm perform on these?**\n",
    "\n",
    "**If no such input cases are available (or in addition to such input cases), how does the algorithm perform on simulated data sets for which you know the \"truth\"?**\n",
    "\n",
    "We include two simulated examples with known target distributions from which the sampler should be drawing. The first, from the Chen et al. paper, samples from the target distribution with $U(\\theta) = -2\\theta^2 + \\theta^4.$ For the SGHMC we use artificially injected gradient noise; specifically, we set $\\Delta \\tilde{U}(\\theta)=\\Delta U(\\theta) + \\mathcal{N}(0,4).$ **FIXME** give full details of initialization settings. \n",
    "\n",
    "The second example samples the mean parameters of a mixture of normals distribution. **FIXME** describe this more.\n",
    "\n",
    "**FIXME** describe how we do mini-batching.\n",
    "\n",
    "**FIXME** show results for both examples of using the SGHMC algorithm; add the \"true\" density for Fig 1 example, and the MLE for Mix of normals example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications to real data sets\n",
    "\n",
    "**Test the algorithm on the real-world examples in the orignal paper if possible. Try to find at least one other real-world data set not in the original paper and test it on that. Describe and interpret the results.**\n",
    "\n",
    "We still need to pick a real data set (maybe some kind of regression data set)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparative analysis with competing algorihtms\n",
    "\n",
    "**Find two other algorihtms that addresss a similar problem. Perform a comparison - for example, of accurary or speed. You can use native libraires of the other algorithms - you do not need to code them yourself. Comment on your observations.**\n",
    "\n",
    "We compare the SGHMC method (as coded by us) to both the standard HMC method as implemented in the package `pyhmc`, and to **FIXME** figure out second comparison (maybe Stan?).\n",
    "\n",
    "Things to talk about: `pyhmc` is suuuuper slow at sampling when we have a gradient calculation with lots of data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion/conclusion\n",
    "\n",
    "**Your thoughts on the algorithm. Does it fulfill a particular need? How could it be generalized to other problem domains? What are its limiations and how could it be improved further?**\n",
    "\n",
    "Things to talk about: the tuning parameters in the SGHMC seem very fiddly. I wouldn't trust it when it came to sampling a target distribution I knew nothing about...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References/bibliography\n",
    "\n",
    "Make sure you cite your sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "The code should be in a public GitHub repository with:\n",
    "\n",
    "1. A README file\n",
    "2. An open source license\n",
    "3. Source code\n",
    "4. Test code\n",
    "5. Examples\n",
    "6. A reproducible report\n",
    "\n",
    "The package should be downloadable and installable with `python setup.py install`, or even posted to PyPI adn installable with `pip install package`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rubric\n",
    "\n",
    "Each item is worth 10 points, but some sections will give up to 10 bonus points if done really well. Note that the \"difficulty factor\" of the chosen algorithm will be factored into the grading. \n",
    "\n",
    "1. Is the abstract, background and discussion readable and clear? (10-20 points)\n",
    "2. Is the algorithm description clear and accurate? (10-20 points)\n",
    "3. Has the algorihtm been optimized? (10-20 points)\n",
    "4. Are the applicaitons to simulated/real data clear and useful? (10-20 points)\n",
    "5. Was the comarative analysis done well? (10-20 points points)\n",
    "6. Is there a well-maitnatined Github repository for the code? (10 points)\n",
    "7. Is the document show evidenc of literate programming? (10 points)\n",
    "8. Is the analyiss reproducible? (10 points)\n",
    "9. Is the code tested? Are examples provided? (10 points)\n",
    "10. Is the package easily installable? (10 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
